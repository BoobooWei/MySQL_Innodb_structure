[TOC]

# 索引与算法

## innodb存储引擎 索引概述

支持：
    B+树索引
    全文索引
    HASH索引

```powershell
InnoDB存储引擎支持两种常见的索引，一种是B+树索引，另一种是哈希索引。InnoDB存储引擎支持的哈希索引是自适应的，InnoDB存储引擎会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。
```



```powershell
B+树索引就是传统意义上的索引，这是目前关系型数据库系统中最常用、最有效的索引。B+树索引的构造类似于二叉树，根据键值（Key Value）快速找到数据。需要注意的是，B+树中的B不是代表二叉（binary），而是代表平衡（balance），因为B+树是从最早的平衡二叉树演化而来，但是B+树不是一个二叉树。
```

注意： B+树索引并不能找到具体的行，只能找到被找的行所在的页，把页读到内存，再在内存当中查找。

## 数据结构和算法

### 二分查找法

```sql
二分查找法（binary search）也称为折半查找法，用来查找一组有序的记录数组中的某一记录。其基本思想是：将记录按有序化（递增或递减）排列，查找过程中采用跳跃式方式查找，即先以有序数列的中点位置为比较对象，如果要找的元素值小于该中点元素，则将待查序列缩小为左半部分，否则为右半部分。通过一次比较，将查找区间缩小一半。
```

### 二叉树和平衡二叉树

```sql
二叉树：
左子树的键值总是小于根的键值，右子树的键值总是大于根的键值。

若想要构造一颗性能最大的二叉树，需要这颗二叉树是平衡的，称为平衡二叉树；
平衡二叉树的定义：满足二叉树的定义，同时任何节点的两个子树的高度差最大为1。

一颗AVL树的维护是需要一定的开销的
```

## B+树

```SQL
所有记录节点都是按键值的大小顺序存放在同一层的叶节点中，各叶节点指针进行连接。
```

### B+树的插入操作       

```SQL
为了保持B+树的平衡，对于新插入的键值可能需要做大量的拆分页（spit）的操作。为了减少拆分操作，B+树同样提供类似于二叉树的旋转功能。
        
在叶子节点满的情况，但是他的左右兄弟节点没有满的情况。这时B+树不会急于拆分，而是去做旋转操作
```



### B+树的删除操作

```sql
B+树使用填充因子来控制数的删除变化，50%是填充因子可设置的最小值。
注意： 填充因子表示页的填充率
```



## B+树索引

```sql 
    分为：
    聚集索引
    辅助索引
    
    B+索引在数据库中有一个特点就是其高扇出性，因此在数据库中，B+树的高度一般都在2～3层;
    不管是聚集还是非聚集的索引，其内部都是B+树的，即高度平衡的，叶节点存放着所有的数据。聚集索引与非聚集索引不同的是，叶节点存放的是否是一整行的信息。
```



### 聚集索引

```sql
聚集索引是按照每张表的主键构造的一颗B+树，同时叶子节点存放的即是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。
这个特性决定了索引组织表中的数据也是索引的一部分。每个数据页都是通过双向链表来进行连接。

每张表只能有一个聚集索引。
聚集索引不是物理上连续的，是逻辑上连续的。

优点：
聚集索引的好处是，对于主键的排序查找和范围查找速度非常快。
```


### 辅助索引

```SQL
原理：
辅助索引（也称非聚集索引），叶级别不包含行的全部数据。叶节点除了包含键值以外，每个叶级别中的索引行中还包含了一个书签（bookmark），该书签用来告诉InnoDB存储引擎，哪里可以找到与索引相对应的行数据。因为InnoDB存储引擎表是索引组织表，因此InnoDB存储引擎的辅助索引的书签就是相应行数据的聚集索引键。显示了InnoDB存储引擎中辅助索引与聚集索引的关系。

辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录。

对于其他的一些数据库，如Microsoft SQL Server数据库，其表类型有一种不是索引组织表，称为堆表。堆表的特性决定了堆表上的索引都是非聚集的，但是堆表没有主键。因此这时书签是一个行标识符（row identifier，RID），可以用如“文件号：页号：槽号”的格式来定位实际的行。

注意点：
堆表的书签性使得非聚集查找可以比主键书签方式更快，并且非聚集可能在一张表中存在多个，我们需要对多个非聚集索引的查找。而且对于非聚集索引的离散读取，索引组织表上的非聚集索引会比堆表上的聚集索引慢一些。
此外另一个不能忽视的是对于排序和范围查找，索引组织表可以通过B+树的中间节点就找到要查找的所有页，然后进行读取，而堆表的特性决定了这对其是不能实现的。


```


### B+树索引的分裂

 

```sql
INNODB 插入时，首先需要进行定位 定位到的记录为待插入记录的前一条记录 ，若之后还有3条记录，则分裂点为定位到的记录后的第三条记录。
否则 分裂点记录就是待插入记录

注意：
从中间分裂，造成相当的空间良妃
```



### B+树索引的管理

```sql
1）语法：
ALTER TABLE tbl_name
|ADD{INDEX|KEY}[index_name]
[index_type] (index_col_name，……) [index_option]……

ALTER TABLE tbl_name
DROP PRIMARY KEY
|DROP {INDEX|KEY} index_name

CREATE/DROP INDEX的语法同样很简单：

CREATE [UNIQUE] INDEX index_name
[index_type]
ON tbl_name（index_col_name，……）

DROP INDEX index_name ON tbl_name

例子：
索引管理
   create table etest ( a INT not null, b varchar(8000), c INT not null, primary key (a) ) engine=innodb;
   insert into etest select 1,repeat('a',7000),-1;
   insert into etest select 2,repeat('a',7000),-2;
   insert into etest select 3,repeat('a',7000),-3;
   insert into etest select 4,repeat('a',7000),-4;

   添加b列索引，只索引前100个字段
   alter table etest add key idx_b (b(100));

   添加a，c的联合索引
   alter table etest add key idx_a_c (a,c);

   查看表的索引
mysql> show index from etest\G;
*************************** 1. row ***************************
        Table: etest
   Non_unique: 0
     Key_name: PRIMARY
Seq_in_index: 1
  Column_name: a
    Collation: A
  Cardinality: 4
     Sub_part: NULL
       Packed: NULL
         Null:
   Index_type: BTREE
      Comment:
Index_comment:
*************************** 2. row ***************************
        Table: etest
   Non_unique: 1
     Key_name: idx_b
Seq_in_index: 1
  Column_name: b
    Collation: A
  Cardinality: 1
     Sub_part: 100
       Packed: NULL
         Null: YES
   Index_type: BTREE
      Comment:
Index_comment:
*************************** 3. row ***************************
        Table: etest
   Non_unique: 1
     Key_name: idx_a_c
Seq_in_index: 1
  Column_name: a
    Collation: A
  Cardinality: 4
     Sub_part: NULL
       Packed: NULL
         Null:
   Index_type: BTREE
      Comment:
Index_comment:
*************************** 4. row ***************************
        Table: etest
   Non_unique: 1
     Key_name: idx_a_c
Seq_in_index: 2
  Column_name: c
    Collation: A
  Cardinality: 4
     Sub_part: NULL
       Packed: NULL
         Null:
   Index_type: BTREE
      Comment:
Index_comment:
每列的含义：
--Table：索引所在的表名。
--Non_unique：非唯一的索引，可以看到primary key是0，因为必须是唯一的。
--Key_name：索引的名称，我们可以通过这个名称来DROP INDEX。
--Seq_in_index：索引中该列的位置，如果看联合索引idx_a_b就比较直观了。
--Column_name：索引的列
--Collation：列以什么方式存储在索引中。可以是'A'或者NULL。B+树索引总是A，即排序的。如果使用了Heap存储引擎，并且建立了Hash索引，这里就会显示NULL了。因为Hash根据Hash桶来存放索引数据，而不是对数据进行排序。
--Cardinality：非常关键的值，表示索引中唯一值的数目的估计值。Cardinality/表的行数应尽可能接近1，如果非常小，那么需要考虑是否还需要建这个索引。
--Sub_part：是否是列的部分被索引。如果看idx_b这个索引，这里显示100，表示我们只索引b列的前100个字符。如果索引整个列，则该字段为NULL。
--Packed：关键字如何被压缩。如果没有被压缩，则为NULL。
--Null：是否索引的列含有NULL值。可以看到idx_b这里为Yes。因为我们定义的b列允许NULL值。
--Index_type：索引的类型。InnoDB存储引擎只支持B+树索引，所以这里显示的都是BTREE。
--Comment：注释。


2）注意：
---cardinality
Cardinality为NULL，在某些情况下可能会发生索引建立了、但是没有用到，或者explain两条基本一样的语句，但是最终出来的结果不一样。一个使用索引，另外一个使用全表扫描，这时最好的解决办法就是做一次ANALYZE TABLE的操作。因此我建议在一个非高峰时间，对应用程序下的几张核心表做ANALYZE TABLE操作，这能使优化器和索引更好地为你工作。


3）fast index creation
对于辅助索引的创建，InnoDB存储引擎会对表加上一个S锁。在创建的过程中，不需要重建表，因此速度极快。但是在创建的过程中，由于上了S锁，因此创建的过程中该表只能进行读操作。删除辅助索引操作就更简单了，只需在InnoDB存储引擎的内部视图更新下，将辅助索引的空间标记为可用，并删除MySQL内部视图上对于该表的索引定义即可。

当然这种方法只限定于辅助索引，对于主键的创建和删除还是需要重建一张表。

4）online schema change
在线架构改变，是一个PHP脚本


5） online DDL
    5.6版本开始支持数据库在线定义操作
    语法：
ALTER TABLE tbl_name
|ADD{INDEX|KEY}[index_name]
[index_type] (index_col_name，……) [index_option]……
ALGORITHM [=] {default|inplace|copy}
lock [=] {default|none|shared|exclusive}

ALGORITHM 的default参数根据：
mysql> show variables like 'old_alter_table';
+-----------------+-------+
| Variable_name   | Value |
+-----------------+-------+
| old_alter_table | OFF   |
+-----------------+-------+
来选择：off选择inplace on选择copy

原理：在执行DDL操作的同时，将DML操作日志写入缓存当中，待索引创建完成之后，再重做应用到表上。
     缓存大小由innodb_online_alter_log_max_size控制。
     
mysql> show variables like 'innodb_online_alter_log_max_size';
+----------------------------------+-----------+
| Variable_name                    | Value     |
+----------------------------------+-----------+
| innodb_online_alter_log_max_size | 134217728 |
+----------------------------------+-----------+


```

   

## cardinality值

*************************************************************************************************************
```sql
定义：
Cardinality：基数，不重复记录的预估值。在实际应用中，Cardinality/n_row_in_table应尽可能的接近1，如果非常小,那用户需要考虑是否还有必要创建这个索引
    
    


如果需要更新索引的cardinality值，使用：
mysql> analyze table etest; 
但是此操作代价大，建议非业务高峰期使用。使得优化器和索引更好作用

原理：
Cardinality值通过对8个叶子节点预估而得的。而不是一个实际精确的值。

cardinality值的统计是通过采样的方式完成的。
   在INSERT和UPDATE时，会发生cardinality值的更新。他的策略是：
   1 表中1/6的数据已经发生变化
   2 stat_modified_counter>2000 000 000
   注释：第二种策略是表中某一行数据频繁更新，用来表示数据更新的次数。
   
   Cardinality值通过对8个叶子节点预估而得的。而不是一个实际精确的值。通过：
   show index from tablename会触发数据库对cardinality值的统计，发现每次运行的结果不一样。

mysql> show variables like 'innodb_stats_sample_pages';  用来控制每次采样页的数量
+---------------------------+-------+
| Variable_name             | Value |
+---------------------------+-------+
| innodb_stats_sample_pages | 8     |
+---------------------------+-------+
   采样时对NULL的处理：
mysql> show variables like 'innodb_stats_method';
+---------------------+-------------+
| Variable_name       | Value       |
+---------------------+-------------+
| innodb_stats_method | nulls_equal |
+---------------------+-------------+
nulls_equal：将NULL视为相等的记录
nulls_unequal：视为不相等
nulls_ignored： 忽略NULL

新增参数：
mysql> show variables like 'innodb_stats_on_metadata';
+--------------------------+-------+
| Variable_name            | Value |
+--------------------------+-------+
| innodb_stats_on_metadata | OFF   |
+--------------------------+-------+
--show table status/show index是否计算cardinality值

mysql> show variables like 'innodb_stats_persistent';
+-------------------------+-------+
| Variable_name           | Value |
+-------------------------+-------+
| innodb_stats_persistent | ON    |
+-------------------------+-------+
1 row in set (0.00 sec)
--是否启用持久化统计信息功能
mysql> show variables like 'innodb_stats_persistent%';
+--------------------------------------+-------+
| Variable_name                        | Value |
+--------------------------------------+-------+
| innodb_stats_persistent              | ON    |
| innodb_stats_persistent_sample_pages | 20    | --analyze table的采样的pages
+--------------------------------------+-------+
2 rows in set (0.00 sec)

mysql> show variables like 'innodb_stats_auto_recalc';
+--------------------------+-------+
| Variable_name            | Value |
+--------------------------+-------+
| innodb_stats_auto_recalc | ON    |
+--------------------------+-------+
--是否自动触发更新统计信息
```



## B+树索引的使用

******************************************************************************************************************
```sql
索引使用的原则，即高选择、取出表中少部分的数据。

1）原理：
顺序读、随机读与预读取

顺序读（Sequntial Read）是指顺序地读取磁盘上的块（Block）。
随机读（Random Read）是指访问的块不是连续的，需要磁盘的磁头不断移动。
--磁盘的随机读性能都远远小于顺序读的性能。

在数据库中，顺序读是指根据索引的叶节点数据就能顺序地读取所需的行数据。这个顺序只是逻辑地顺序读，在物理磁盘上可能还是随机读取。但是相对来说，物理磁盘上的数据还是比较顺序的，因为是根据区来管理的，区是64个连续页。如根据主键进行读取，或许通过辅助索引的叶节点就能读取到数据。

随机读，一般是指访问辅助索引叶节点不能完全得到结果的，需要根据辅助索引叶节点中的主键去找实际行数据。因为一般来说，辅助索引和主键所在的数据段不同，因此访问是随机的方式。

为了提高读取的性能，InnoDB存储引擎引入了预读取技术（read ahead或者prefetch）。预读取是指通过一次IO请求将多个页预读取到缓冲池中，并且估计预读取的多个页马上会被访问。传统的IO请求每次只读取1个页，在传统机械硬盘较低的IOPS下，预读技术可以大大提高读取的性能。



2）联合索引
好处1：where条件包含 "and" 连接的多个索引列，可以直接使用索引
好处2：可以对第二个键值进行排序

实验：

1 创建测试表并且插入数据
create table buy_log(
user_id INT unsigned not null,
buy_date date)
engine=innodb;

mysql> insert into buy_log values (1,'2009-01-01');
mysql> insert into buy_log values (2,'2009-01-01');
mysql> insert into buy_log values (3,'2009-01-01');
mysql> insert into buy_log values (1,'2009-02-01');
mysql> insert into buy_log values (3,'2009-02-01');
mysql> insert into buy_log values (1,'2009-03-01');
mysql> insert into buy_log values (1,'2009-04-01');

2 添加索引和联合索引
mysql> alter table buy_log add key (user_id);
mysql> alter table buy_log add key (user_id,buy_date);

3 查看索引执行计划
mysql> explain  select * from buy_log where user_id=2;
+----+-------------+---------+------------+------+-------------------+---------+---------+-------+------+----------+-------+
| id | select_type | table   | partitions | type | possible_keys     | key     | key_len | ref   | rows | filtered | Extra |
+----+-------------+---------+------------+------+-------------------+---------+---------+-------+------+----------+-------+
|  1 | SIMPLE      | buy_log | NULL       | ref  | user_id,user_id_2 | user_id | 4       | const |    1 |   100.00 | NULL  |
+----+-------------+---------+------------+------+-------------------+---------+---------+-------+------+----------+-------+
1 row in set, 1 warning (0.00 sec)

mysql> explain  select * from buy_log where user_id=1 order by buy_date limit 3;
+----+-------------+---------+------------+------+-------------------+-----------+---------+-------+------+----------+--------------------------+
| id | select_type | table   | partitions | type | possible_keys     | key       | key_len | ref   | rows | filtered | Extra                    |
+----+-------------+---------+------------+------+-------------------+-----------+---------+-------+------+----------+--------------------------+
|  1 | SIMPLE      | buy_log | NULL       | ref  | user_id,user_id_2 | user_id_2 | 4       | const |    4 |   100.00 | Using where; Using index |
+----+-------------+---------+------------+------+-------------------+-----------+---------+-------+------+----------+--------------------------+
1 row in set, 1 warning (0.00 sec)

注释：若在第二种情况下，强行使用user_id索引，会对buy_date进行一次额外的排序动作才能完成查询。


3）覆盖索引

    从辅助索引中就可以得到查询结果，而不需要查询聚集索引当中的记录。使用覆盖索引的好处是，辅助索引远小于聚集索引，因此可以减少大量的IO
    
（1）索引条目通常远小于数据行大小，如果只读取索引，MySQL就会极大地减少数据访问量。
（2）索引按照列值顺序存储，对于I/O密集的范围查询会比随机从磁盘中读取每一行数据的I/O要少很多。
（3）InnoDB的辅助索引（亦称二级索引）在叶子节点中保存了行的主键值，如果二级索引能够覆盖查询，则可不必对主键索引进行二次查询了。
覆盖索引就是从索引中直接获取查询结果，要使用覆盖索引需要注意select查询列中包含在索引列中；
where条件包含索引列或者复合索引的前导列；查询结果的字段长度尽可能少


4） 优化器选择不使用索引的情况
    这种情况多发生在范围查找，join连接等操作。

注释：对于用户要选取的数据时整行信息，而辅助索引不能覆盖到。因此，在对辅助索引查询到指定数据之后，还需要一次书签访问来查到整行信息。
虽然辅助索引中的数据时顺序存放，但再进行一次书签查找的数据则是无序的（磁盘的离散读）。
若要求返回的数据量很小，则优化器还是会选择辅助索引；
但是要求返回的数据占比较大（20%左右） 优化器会选择通过聚集索引来查找数据。（因为顺序读速度大于离散读）

若是对使用辅助索引能带来更好的性能确信，使用force index
如：select * from orders force index(order_id) where order_id > 10000 and order_id < 10200;



5） 索引提示
INDEX HINT 显式告诉优化器需要使用哪个索引。
使用情况：
   1   优化器错误的选择某个索引
   2   优化器可以选择的索引很多，导致选择执行计划的时间开销大于SQL本身

指定某个索引最可靠方法是force index

6）  Multi-range read 优化（MRR）
     MRR优化可适用于rangeref,eq_ref类型的查询
     优势：
     a)MRR使数据访问变得较为顺序。在查询辅助索引时，首先根据得到的查询结果按照主键进行排序，并按照主键排序      的顺序进行书签查找
     b)减少缓冲池中页被替换的次数
     c)批量处理对键值的查询操作



    工作原理：
    对于InnoDB和MyISAM存储引擎的范围查询和JOIN查询操作，MRR工作方式如下
    a)将查询得到的辅助索引键值存放在一个缓存中，这是缓存中的数据是根据辅助索引键值排序的
    b)将缓存中的键值根据RowID进行排序
    c)根据RowID的排序顺序来访问实际的数据文件
    d)此外，MRR还可以将某些范围查询拆分为键值对，在拆分的过程当中，直接过滤掉一些不符合条件的数据
    例子：
    SELECT * FROM t WHERE key_part1>=1000 and key_part1<2000 AND key_part2=1000;
    表t有(key_part1,key_part2)的联合索引因此索引根据key_part1,key_part2的位置关系进行排序。若没有MRR，此     时查询类型为Range。SQL优化器会先将key_part1>1000 and key_part2<2000的数据线取出来，即使key_part2不     等于1000。待取出的行数据后在根据key_part2的条件进行过滤，这会导致无用的数据被取出，如果有大量的数据且其     key_part2不等于1000，则启用MRR优化会使性能有巨大的提升 

    启用MRR优化，优化器会先将查询条件进行拆分，然后在进行数据查询。上述语句，优化器会将查询条件拆分为      (1000,1000),(1001,1000),(1002,1000),...,(1999,1000)，然后在根据这些拆分出的条件进行数据查询
    
    
    
    参数：
    参数read_rnd_buffer_size用来控制键值的缓冲区大小,当大于该值，执行器对已经缓存的数据根据RowID进行排序，并通过RowID来取得行数据。该值默认为256K
    mysql> select @@optimizer_switch\G;
    mysql> set  @@optimizer_switch='mrr=on,mrr_cost_based=off';  将mrr优化总是设置为开启状态
    
    
7） index condition pushdown （ICP）优化
    
在进行索引查询的时候，首先根据索引来查找记录，然后再根据where条件来过滤。
在支持ICP之后，mysql数据库会在取出索引的同时，来判断是否可以进行where条件的过滤，也就是将where条件的过滤放在了存储引擎层。
这样可以减少上层SQL对记录的索取，从而提高数据库的性能。

注意点:
a) create index idx_userid_order_id_createdate on test_order(user_id,order_id,create_date);
查询语句为：select * from test_order where user_id = 500 and create_date > '2015-1-1';
第二个筛选条件是无法直接使用索引的 :
执行计划中extra中使用using index condition

b) ICP的前提两个查询条件包被索引覆盖，但是次选条件无法直接使用索引查找，如果次选条件没有被索引覆盖，是无法得知次选条件的值的，也就无从 索引条件下推优化了。 
```



## HASH索引


```sql
1 哈希表
    利用hash函数将关键字映射到哈希表的槽位上。（数据库采用链表发来处理两个关键字映射到同一个槽位上的碰撞）
    h(k) = k mod m

2 innodb 中的hash算法
    --INNODB 存储引擎使用hash算法来对字典进行查找，采用链表对付碰撞，采用除法散列。

    InnoDB存储引擎使用哈希算法对字典进行查找，其冲突机制采用链表方式，哈希函数采用除法散列方式。对于缓冲池页的哈希表来说，在缓冲池中的Page页都有一个chain指针，它指向相同哈希函数值的页。而对于除法散列，m的取值为略大于2倍的缓冲池页数量的质数。

例如：当前参数innodb_buffer_pool_size的设置大小为10MB，则共有640个16KB的页。那对于缓冲池页内存的哈希表来说，需要分配640×2=1280个槽，但是1280不是质数，需要取比1 280略大的一个质数，应该是1399，所以在启动时会分配1399个槽的哈希表，用来哈希查询所在缓冲池中的页。哈希表本身需要20个字节，每个槽需要4个字节，因此一共需要20+4×1399=5616个字节。其中哈希表的20个字节从innodb_additional_mem_pool_size中进行分配，4×1399=5596个字节从系统申请分配。因此在对InnoDB存储引擎进行内存分配规划时，也应该规划好哈希表这部分内存，这部分内存一般从系统分配，没有参数可以控制。对于前面我们说的128GB的缓冲池内存，则分配的哈希表和槽一共需要差不多640MB的额外内存空间。

那InnoDB存储引擎对于页是怎么进行查找的呢？上面只是给出了一般的算法，怎么将要查找的页转换成自然数呢？

InnoDB存储引擎的表空间都有一个space号，我们要查的应该是某个表空间的某个连续16KB的页，即偏移量offset。InnoDB存储引擎将space左移20位，然后加上这个space和offset，即关键字K=space<<20+space+offset，然后通过除法散列到各个槽中。
    


 3 自适应哈希索引
    是有数据库自身创建并且使用的，DBA本身不能对其进行干预。对于范围查找无能为力。

  
```





## 全文检索


```sql
1 概述
    B+树 可以通过索引字段的前缀进行查找  例如：
    select * from blog where content like 'XXX%'
    不支持：
    select * from blog where content like '%XXX%'

    全文检索是将存储于数据库中的整本书会整篇文章中的任意内容信息查找出来的技术

2 倒排索引

    全文检索通常通过倒排索引来实现。
    它是在辅助表中存储了单词与单词自身在一个或多个文档所在位置之间的映射。其有两种表现形式：
    1 inverted file index  ： 单词，单词所在文档的ID
    2 full inverted index  ： 单词，（单词所在文档的ID，在文档当中的具体位置）
    
    
3  INNODB 全文检索
    在innodb中 将（documentID ，position）视为“ilist”，因此全文检索的表中有两个列，Word 和 ilist。
    倒排索引将Word放进辅助表（Auxiliary table）;为了提高并行性能 共有6张辅助表。每张表根据Word的Latin编码进行分区。

    Auxiliary table是持久表，存于硬盘。因此为了提高全文检索的性能，使用全文检索索引缓存（FTS index cache）
    
    
1)原理：
        DQL：
        FTS index cache是红黑树结构,innoDB会批量对辅助表进行更新。在全文检索查询的时候，Auxiliary Table首先会把 FTS index cache中的
        对应的Word字段合并到辅助表当中，然后再查询。提高了innodb的性能，由于是根据红黑树插入，其产生的辅助表很小。
        DML：
        对于innodb而言，其总是在事务提交时将分词写入FTS index cache，然后再批量写入到磁盘。上述操作只是在事务提交时发生。
        数据库关闭时，FTS index cache中的数据会同步到磁盘上的辅助表。
        插入操作是在事务提交的时候完成；
        对于删除操作：
        当提交删除数据的事务以后，不会删除Auxiliary Table中的数据，而只会删除FTS Index Cache中的数据。
        对于Auxiliary Table中被删除的记录，InnoDB存储引擎会记录其FTS Document Id，并将其保存在DELETED Auxiliary Table中。
        可以通过OPTIMIZE TABLE手动删除索引中的记录。
        注意：opimize table 不仅会删除索引中的记录，还会重新统计cardinality的值；
        

    当数据库宕机，一些FTS index cache中的数据可能未被同步到磁盘，下次重启时，当用户对表进行全文检索（查询插入）时 ，
    innodb会自动读取未完成的文档，然后进行分词操作，将分词结果放在fts index cache中。
    注释：
    -rw-r-----  1 mysql mysql   98304 Mar 14 10:02 FTS_0000000000000094_CONFIG.ibd
    此文件包含全文索引的内部信息，最重要的存储是FTS_SYNCED_DOC_ID，表示已经解析并刷到磁盘的FTS_DOC_ID，
    在系统宕机时，可以根据这个值判断哪些该重新分词并加入到FTS Index Cache中
    
    FTS Document ID:
    当表上存在全文索引时，就会隐式的建立一个名为FTS_DOC_ID的列，并在其上创建一个唯一索引，用于标识分词出现的记录行。
    你也可以显式的创建一个名为FTS_DOC_ID的列，但需要和隐式创建的列类型保持一致(bigint unsigned auto_increment not null)，否则创建的时候将会报错，并且不能通过FTS_DOC_ID来查找列。
    
    
  
2) 参数：
mysql> show variables like 'innodb_optimize_fulltext_only';
+-------------------------------+-------+
| Variable_name                 | Value |
+-------------------------------+-------+
| innodb_optimize_fulltext_only | OFF   |
+-------------------------------+-------+
1 row in set (0.00 sec)

mysql> set global innodb_optimize_fulltext_only=1;
Query OK, 0 rows affected (0.00 sec)

mysql> show variables like 'innodb_optimize_fulltext_only';
+-------------------------------+-------+
| Variable_name                 | Value |
+-------------------------------+-------+
| innodb_optimize_fulltext_only | ON    |
+-------------------------------+-------+
设置为只对倒排索引进行操作。防止optimize table影响其他性能！
mysql> show variables like 'innodb_ft_num_word_optimize';
+-----------------------------+-------+
| Variable_name               | Value |
+-----------------------------+-------+
| innodb_ft_num_word_optimize | 2000  |
+-----------------------------+-------+
此参数控制每次实际删除分词的数量。

mysql> show variables like 'innodb_ft_cache%';
通过此参数控制FTS index cache的大小，增大提高性能，宕机时，恢复时间变长    


3) 实验1：FTS index cache实验
    
一 创建测试表       
mysql> create table fts_a( FTS_DOC_ID bigint unsigned auto_increment not null, body text, primary key(FTS_DOC_ID) );
Query OK, 0 rows affected (0.03 sec)

mysql> show index from fts_a\G;
*************************** 1. row ***************************
        Table: fts_a
   Non_unique: 0
     Key_name: PRIMARY
Seq_in_index: 1
  Column_name: FTS_DOC_ID
    Collation: A
  Cardinality: 0
     Sub_part: NULL
       Packed: NULL
         Null:
   Index_type: BTREE
      Comment:
Index_comment:



二 在表中插入相关的数据
mysql> inser into fts_a select NULL,'please porridge in the pot';
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'inser into fts_a select NULL,'please porridge in the pot'' at line 1
mysql> insert into fts_a select NULL,'please porridge in the pot';
Query OK, 1 row affected (0.00 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql> insert into fts_a select NULL,'please porridge hot,please porridge cold';
Query OK, 1 row affected (0.00 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql> insert into fts_a select NULL,'some like it hot,some like it cold';
Query OK, 1 row affected (0.01 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql> insert into fts_a select NULL,'some like it in the pot';
Query OK, 1 row affected (0.00 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql> insert into fts_a select NULL,'nine days old';
Query OK, 1 row affected (0.00 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql> insert into fts_a select NULL,'I like code days';
Query OK, 1 row affected (0.00 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql> select * from fts_a;
+------------+------------------------------------------+
| FTS_DOC_ID | body                                     |
+------------+------------------------------------------+
|          1 | please porridge in the pot               |
|          2 | please porridge hot,please porridge cold |
|          3 | some like it hot,some like it cold       |
|          4 | some like it in the pot                  |
|          5 | nine days old                            |
|          6 | I like code days                         |
+------------+------------------------------------------+
6 rows in set (0.00 sec)

三 创建fulltext索引
mysql> create fulltext index idx_fts_body on fts_a(body);
Query OK, 0 rows affected (0.15 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql> show index from fts_a\G;
*************************** 1. row ***************************
        Table: fts_a
   Non_unique: 0
     Key_name: PRIMARY
Seq_in_index: 1
  Column_name: FTS_DOC_ID
    Collation: A
  Cardinality: 6
     Sub_part: NULL
       Packed: NULL
         Null:
   Index_type: BTREE
      Comment:
Index_comment:
*************************** 2. row ***************************
        Table: fts_a
   Non_unique: 1
     Key_name: idx_fts_body
Seq_in_index: 1
  Column_name: body
    Collation: NULL
  Cardinality: 6
     Sub_part: NULL
       Packed: NULL
         Null: YES
   Index_type: FULLTEXT
      Comment:
Index_comment:
2 rows in set (0.00 sec)



四  设置innodb_ft_aux_table参数 并且查看分词信息
mysql> set global innodb_ft_aux_table='db100/fts_a';
Query OK, 0 rows affected (0.00 sec)

mysql> select * from information_schema.innodb_ft_index_table;
+----------+--------------+-------------+-----------+--------+----------+
| WORD     | FIRST_DOC_ID | LAST_DOC_ID | DOC_COUNT | DOC_ID | POSITION |
+----------+--------------+-------------+-----------+--------+----------+
| code     |            6 |           6 |         1 |      6 |        7 |
| cold     |            2 |           3 |         2 |      2 |       36 |
| cold     |            2 |           3 |         2 |      3 |       30 |
| days     |            5 |           6 |         2 |      5 |        5 |
| days     |            5 |           6 |         2 |      6 |       12 |
| hot      |            2 |           3 |         2 |      2 |       16 |
| hot      |            2 |           3 |         2 |      3 |       13 |
| like     |            3 |           6 |         3 |      3 |        5 |
| like     |            3 |           6 |         3 |      3 |       17 |
| like     |            3 |           6 |         3 |      4 |        5 |
| like     |            3 |           6 |         3 |      6 |        2 |
| nine     |            5 |           5 |         1 |      5 |        0 |
| old      |            5 |           5 |         1 |      5 |       10 |
| please   |            1 |           2 |         2 |      1 |        0 |
| please   |            1 |           2 |         2 |      2 |        0 |
| please   |            1 |           2 |         2 |      2 |       20 |
| porridge |            1 |           2 |         2 |      1 |        7 |
| porridge |            1 |           2 |         2 |      2 |        7 |
| porridge |            1 |           2 |         2 |      2 |       20 |
| pot      |            1 |           4 |         2 |      1 |       23 |
| pot      |            1 |           4 |         2 |      4 |       20 |
| some     |            3 |           4 |         2 |      3 |        0 |
| some     |            3 |           4 |         2 |      3 |       17 |
| some     |            3 |           4 |         2 |      4 |        0 |
+----------+--------------+-------------+-----------+--------+----------+
24 rows in set (0.00 sec)

mysql> select * from fts_a where FTS_DOC_ID=6;
+------------+------------------+
| FTS_DOC_ID | body             |
+------------+------------------+
|          6 | I like code days |
+------------+------------------+

五  删除ID=6的记录  查看删除记录插入到delete表
delete from fts_a where FTS_DOC_ID=6;

mysql> SELECT * FROM information_schema.`INNODB_FT_DELETED`;
+--------+
| DOC_ID |
+--------+
|      6 |
+--------+

六  优化表 查看彻底删除的being deleted表
mysql> optimize table db100.fts_a;
+-------------+----------+----------+----------+
| Table       | Op       | Msg_type | Msg_text |
+-------------+----------+----------+----------+
| db100.fts_a | optimize | status   | OK       |
+-------------+----------+----------+----------+

mysql> insert into fts_a select 6,'I like this days';
ERROR 182 (HY000): Invalid InnoDB FTS Doc ID
****即使已经删除记录 也不能插入相同的ID记录到全文检索的表中

mysql> select * from information_schema.innodb_ft_being_deleted;
+--------+
| DOC_ID |
+--------+
|      6 |
+--------+
1 row in set (0.00 sec)



4) stopword
   stopword列表
   stopword list 当中的Word不需要对其进行索引分词操作。可以查看            information_schema.INNODB_FT_DEFAULT_STOPWORD
    
    此外，用户也可以通过参数innodb_ft_server_stopword_table来自定义stopword list:
mysql> create table db100_stopword(value varchar(30)) engine=innodb ;
mysql> set global innodb_ft_server_stopword_table='db100/db100_stopword';


5) 注意：    
    当前innodb的全文索引还有如下限制：
    1  每张表只能有一个全文索引
    2  多列组合的全文索引的索引列必须使用相同的字符集和排序规则
```



## 全文检索的使用


```sql
1） natural language
mysql> select * from fts_a where MATCH (body) against('Porridge' IN NATURAL LANGUAGE MODE);
+------------+------------------------------------------+
| FTS_DOC_ID | body                                     |
+------------+------------------------------------------+
|          2 | please porridge hot,please porridge cold |
|          1 | please porridge in the pot               |
+------------+------------------------------------------+
也可以省略，写成：

mysql> select * from fts_a where MATCH (body) against('Porridge');

在where条件当中，使用match函数，返回结果根据相关性Relevance降序排序。
相关性的依据：
1 Word是否在文档中出现
2 Word在文档中出现的次数
3 Word在索引列中的数量
4 多少个个文档包含Word
如：上述查询结果 第一行数据porridge出现两次，第二行只有一次，因此第一行相关性高

实验1:  统计MATCH函数得到的结果数量：
mysql> select count(*) from fts_a where MATCH (body) against('Porridge');
+----------+
| count(*) |
+----------+
|        2 |
+----------+
1 row in set (0.00 sec)

mysql> select count(if (match(body) against('porridge'),1,null)) as count from fts_a;
第二条SQL的速度更快，因为第一条还要进行相关性的排序。


实验2： 查看相关性
mysql> select fts_doc_id,body,match(body) against ('porridge') as relevance from fts_a;
+------------+------------------------------------------+---------------------+
| fts_doc_id | body                                     | relevance           |
+------------+------------------------------------------+---------------------+
|          1 | please porridge in the pot               | 0.22764469683170319 |
|          2 | please porridge hot,please porridge cold | 0.45528939366340637 |
|          3 | some like it hot,some like it cold       |                   0 |
|          4 | some like it in the pot                  |                   0 |
|          5 | nine days old                            |                   0 |
|          7 | I like this days                         |                   0 |
+------------+------------------------------------------+---------------------+
    使用全文索引，需要考虑一下因素：
        1 查询的Word在stopword当中 忽略该字符串的查询
        2 查询的Word的字符长度在区间[innodb_ft_min_token_size,innodb_ft_max_token_size]内
        
实验3： boolean
mysql> select * from fts_a where match(body) against('+please -hot' IN BOOLEAN MODE);
+------------+----------------------------+
| FTS_DOC_ID | body                       |
+------------+----------------------------+
|          1 | please porridge in the pot |
+------------+----------------------------+
    注意： +表示该Word必须存在 -表示该Word必须去除
    
    
mysql> select * from fts_a where match(body) against('please hot' IN BOOLEAN MODE);
+------------+------------------------------------------+
| FTS_DOC_ID | body                                     |
+------------+------------------------------------------+
|          2 | please porridge hot,please porridge cold |
|          1 | please porridge in the pot               |
|          3 | some like it hot,some like it cold       |
+------------+------------------------------------------+
    不加任何符号，表示或的关系
    
mysql> select * from fts_a where match(body) against('"please pot"@30' IN BOOLEAN MODE);
+------------+----------------------------+
| FTS_DOC_ID | body                       |
+------------+----------------------------+
|          1 | please porridge in the pot |
+------------+----------------------------+
    使用@进行 proximity 查询        表示please pot之间字节数小于30个
    
    
mysql> select fts_doc_id,body ,match(body) against('like >pot' IN BOOLEAN MODE) as relevance from fts_a;
+------------+------------------------------------------+--------------------+
| fts_doc_id | body                                     | relevance          |
+------------+------------------------------------------+--------------------+
|          1 | please porridge in the pot               |  1.227644681930542 |
|          2 | please porridge hot,please porridge cold |                  0 |
|          3 | some like it hot,some like it cold       | 0.1812381148338318 |
|          4 | some like it in the pot                  | 1.3182637691497803 |
|          5 | nine days old                            |                  0 |
|          7 | I like this days                         | 0.0906190574169159 |
+------------+------------------------------------------+--------------------+
6 rows in set (0.00 sec)
    可见>  <是增大和减少相关的作用
    
    
    
mysql> select * from fts_a where match(body) against('po*' IN BOOLEAN MODE);
+------------+------------------------------------------+
| FTS_DOC_ID | body                                     |
+------------+------------------------------------------+
|          2 | please porridge hot,please porridge cold |
|          1 | please porridge in the pot               |
|          4 | some like it in the pot                  |
+------------+------------------------------------------+
    查看文档中含有以po开头的Word
    
    
mysql> select * from fts_a where match(body) against('"like it"' IN BOOLEAN MODE);
+------------+------------------------------------+
| FTS_DOC_ID | body                               |
+------------+------------------------------------+
|          3 | some like it hot,some like it cold |
|          4 | some like it in the pot            |
+------------+------------------------------------+
    ""用来查看文档中含有的短语
    
mysql> select * from fts_a where match(body) against('pot');
+------------+----------------------------+
| FTS_DOC_ID | body                       |
+------------+----------------------------+
|          1 | please porridge in the pot |
|          4 | some like it in the pot    |
+------------+----------------------------+
2 rows in set (0.00 sec)

mysql> select * from fts_a where match(body) against('pot' with query expansion);
+------------+------------------------------------------+
| FTS_DOC_ID | body                                     |
+------------+------------------------------------------+
|          2 | please porridge hot,please porridge cold |
|          1 | please porridge in the pot               |
|          3 | some like it hot,some like it cold       |
|          4 | some like it in the pot                  |
|          7 | I like this days                         |
+------------+------------------------------------------+
5 rows in set (0.00 sec)

全文检索的扩展查询。这种查询通常在查询的关键词太短，用户希望implied knowledge进行扩展查询（显示与关键词相关的结果）



注释：中文的全文检索处理
InnoDB默认的全文索引parser非常合适于Latin，因为Latin是通过空格来分词的。但对于像中文，日文和韩文来说，没有这样的分隔符。
一个词可以由多个字来组成，所以我们需要用不同的方式来处理。在MySQL 5.7.6中我们能使用一个新的全文索引插件来处理它们：n-gram parser。

1 如何在InnoDB中使用N-gram Parser？
N-gram parser是默认加载到MySQL中并可以直接使用的。我们只需要在DDL中创建全文索引时使用WITH PARSER ngram：
mysql > CREATE TABLE articles
(FTS_DOC_ID BIGINT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
title VARCHAR(100),
FULLTEXT INDEX ngram_idx(title) WITH PARSER ngram
) Engine=InnoDB CHARACTER SET utf8mb4;
Query OK, 0 rows affected (0.06 sec)
mysql> # ALTER TABLE articles ADD FULLTEXT INDEX ngram_idx(title) WITH PARSER ngram;
mysql> # CREATE FULLTEXT INDEX ngram_idx ON articles(title) WITH PARSER ngram;

我们引入了一个新的全局变量叫ngram_token_size。由它来决定n-gram中n的大小，也就是词的大小。它的默认值是2，这个时候，我们使用的是bigram。
它的合法的取值范围是1到10。现在，我们很自然会想到一个问题：实际应用中应该如何设置ngram_token_size值的大小呢？当然，我们推荐使用2。
但是你也可以通过如下这个简单的规则来可以选择任何合法的值：设置到你希望能查询到的最小的词的大小。如果你想查询到单个字，那么我们需要设置为1。
ngram_token_size的值设置的越小，全文索引占用的空间也越小。一般来说，查询正好等于ngram_token_size的词，速度会更快，但是查询比它更长的词或短语，则会变慢。

2 N-gram分词处理
N-gram parser和系统默认的全文索引parser有如下不同点：

1） 词大小检查：因为有了ngram_token_size，所以innodb_ft_min_token_size和innodb_ft_max_token_size将不适用于n-gram。

2） 无用词（stopword）处理：通常，对于一个新的词，我们会查找stopwords表，看是否有匹配的词。如果有，这个词就不会加入到全文索引中。
    但是在n-gram中，我们会查找stopwords表，看是否包含里面的词。这样处理的原因是，在中日韩的文本中，有很多没有意义的字符，词语和标点符号。
        比如，如果我们把‘的’加入到stopwords表中，那么对于句子‘信息的系统’，在默认情况下我们分词结果为‘信息’，‘系统’。其中‘息的’和‘的系’被过滤掉了。
```



​      



